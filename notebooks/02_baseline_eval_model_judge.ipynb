{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model-as-a-Judge Evaluation Walkthrough\n",
        "This notebook demonstrates how Riley Inc. can launch an Amazon Bedrock Eval job that uses the Nova Pro model as an evaluator (model-as-a-judge) while benchmarking multiple candidate models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "- AWS credentials configured for the account where evaluations will run.\n",
        "- The IAM role `Amazon-Bedrock-IAM-Role-20250928T210855` with permissions to start Bedrock eval jobs and access the target S3 buckets.\n",
        "- Python environment with the latest `boto3` and `botocore` libraries installed.\n",
        "- The prompt dataset stored in S3 at `s3://riley-inc-rag-knowledge-base-20250929-210517/prompt_datasets/general_trivia_no_groundtruth.jsonl`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "0fdd44f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "import boto3\n",
        "from botocore.exceptions import BotoCoreError, ClientError\n",
        "from copy import deepcopy\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95f19a87",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "Define region, IAM role, dataset location, evaluator model, and the shared output prefix for this evaluation run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bbf7f1b1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation artifacts will be stored under: s3://riley-inc-rag-eval-results-20250929-210517/baseline-evals/model-judge-run-20250929-232500/\n",
            "Using evaluator model: us.amazon.nova-pro-v1:0\n",
            "Datasets: [{'name': 'GeneralTriviaNoGroundTruth', 'datasetLocation': {'s3Uri': 's3://riley-inc-rag-knowledge-base-20250929-210517/prompt_datasets/general_trivia_no_groundtruth.jsonl'}}]\n",
            "Metrics (11): ['Builtin.Correctness', 'Builtin.Completeness', 'Builtin.Faithfulness', 'Builtin.Helpfulness', 'Builtin.Coherence', 'Builtin.Relevance', 'Builtin.FollowingInstructions', 'Builtin.ProfessionalStyleAndTone', 'Builtin.Harmfulness', 'Builtin.Stereotyping', 'Builtin.Refusal']\n"
          ]
        }
      ],
      "source": [
        "aws_region = \"us-west-2\"\n",
        "role_arn = \"arn:aws:iam::187899929471:role/service-role/Amazon-Bedrock-IAM-Role-20250928T210855\"\n",
        "eval_results_bucket = \"riley-inc-rag-eval-results-20250929-210517\"  # Replace with the eval bucket created in 00_infra_setup.ipynb\n",
        "results_prefix = \"baseline-evals/\"\n",
        "prompt_dataset_s3_uri = \"s3://riley-inc-rag-knowledge-base-20250929-210517/prompt_datasets/general_trivia_no_groundtruth.jsonl\"\n",
        "dataset_name = \"GeneralTriviaNoGroundTruth\"\n",
        "datasets = [\n",
        "    {\n",
        "        'name': dataset_name,\n",
        "        'datasetLocation': {'s3Uri': prompt_dataset_s3_uri}\n",
        "    }\n",
        "]\n",
        "core_judge_metrics = [\n",
        "    'Builtin.Correctness',\n",
        "    'Builtin.Completeness',\n",
        "    'Builtin.Faithfulness',\n",
        "    'Builtin.Helpfulness',\n",
        "    'Builtin.Coherence',\n",
        "    'Builtin.Relevance',\n",
        "    'Builtin.FollowingInstructions',\n",
        "    'Builtin.ProfessionalStyleAndTone',\n",
        "]\n",
        "safety_judge_metrics = [\n",
        "    'Builtin.Harmfulness',\n",
        "    'Builtin.Stereotyping',\n",
        "    'Builtin.Refusal',\n",
        "]\n",
        "llm_judge_metrics = core_judge_metrics + safety_judge_metrics\n",
        "judge_task_type = \"General\"\n",
        "primary_model_id = 'us.amazon.nova-lite-v1:0'\n",
        "candidate_models_default = [\n",
        "    'us.amazon.nova-lite-v1:0',\n",
        "    'us.amazon.nova-micro-v1:0',\n",
        "    'us.amazon.nova-pro-v1:0'\n",
        "]\n",
        "evaluator_model_id = 'us.amazon.nova-pro-v1:0'\n",
        "evaluator_model_config = {\n",
        "    'bedrockEvaluatorModels': [\n",
        "        {\n",
        "            'modelIdentifier': evaluator_model_id\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "application_type = 'ModelEvaluation'\n",
        "comparison_run_id = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "shared_output_uri = f\"s3://{eval_results_bucket}/{results_prefix}model-judge-run-{comparison_run_id}/\"\n",
        "\n",
        "if eval_results_bucket.endswith('REPLACE-ME'):\n",
        "    raise ValueError('Update eval_results_bucket with the actual bucket name before running the notebook.')\n",
        "if not datasets or not llm_judge_metrics:\n",
        "    raise ValueError('Datasets and metrics must be non-empty lists.')\n",
        "\n",
        "print(f'Evaluation artifacts will be stored under: {shared_output_uri}')\n",
        "print(f'Using evaluator model: {evaluator_model_id}')\n",
        "print(f'Datasets: {datasets}')\n",
        "print(f'Metrics ({len(llm_judge_metrics)}): {llm_judge_metrics}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97d7b5a6",
      "metadata": {},
      "source": [
        "## Initialize Bedrock Client\n",
        "Establish a client connection to Amazon Bedrock in the selected region."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "75007683",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bedrock client ready.\n"
          ]
        }
      ],
      "source": [
        "bedrock = boto3.client('bedrock', region_name=aws_region)\n",
        "print('Bedrock client ready.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24e783d0",
      "metadata": {},
      "source": [
        "## Submit Baseline Model-as-a-Judge Eval Job\n",
        "Create an evaluation job that uses the Nova Pro evaluator to score a single candidate model against the prompt dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a6083963",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating evaluation job: baseline-eval-job-20250929-232655 → s3://riley-inc-rag-eval-results-20250929-210517/baseline-evals/model-judge-run-20250929-232500/\n",
            "{\n",
            "  \"ResponseMetadata\": {\n",
            "    \"RequestId\": \"9244a0e1-c964-449f-8395-6c060e0a12f1\",\n",
            "    \"HTTPStatusCode\": 202,\n",
            "    \"HTTPHeaders\": {\n",
            "      \"date\": \"Mon, 29 Sep 2025 15:26:56 GMT\",\n",
            "      \"content-type\": \"application/json\",\n",
            "      \"content-length\": \"79\",\n",
            "      \"connection\": \"keep-alive\",\n",
            "      \"x-amzn-requestid\": \"9244a0e1-c964-449f-8395-6c060e0a12f1\"\n",
            "    },\n",
            "    \"RetryAttempts\": 0\n",
            "  },\n",
            "  \"jobArn\": \"arn:aws:bedrock:us-west-2:187899929471:evaluation-job/ks5dd1pskn07\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Build a timestamped job name\n",
        "job_name = f\"baseline-eval-job-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
        "print(f'Creating evaluation job: {job_name} → {shared_output_uri}')\n",
        "\n",
        "dataset_metric_configs = [\n",
        "    {\n",
        "        'taskType': judge_task_type,\n",
        "        'dataset': deepcopy(dataset),\n",
        "        'metricNames': llm_judge_metrics\n",
        "    }\n",
        "    for dataset in datasets\n",
        "]\n",
        "\n",
        "evaluation_request = {\n",
        "    'jobName': job_name,\n",
        "    'roleArn': role_arn,\n",
        "    'applicationType': application_type,\n",
        "    'evaluationConfig': {\n",
        "        'automated': {\n",
        "            'datasetMetricConfigs': dataset_metric_configs,\n",
        "            'evaluatorModelConfig': evaluator_model_config\n",
        "        }\n",
        "    },\n",
        "    'inferenceConfig': {\n",
        "        'models': [\n",
        "            {\n",
        "                'bedrockModel': {\n",
        "                    'modelIdentifier': primary_model_id\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    'outputDataConfig': {'s3Uri': shared_output_uri}\n",
        "}\n",
        "\n",
        "try:\n",
        "    create_response = bedrock.create_evaluation_job(**evaluation_request)\n",
        "    print(json.dumps(create_response, indent=2))\n",
        "except (ClientError, BotoCoreError) as err:\n",
        "    raise RuntimeError('Failed to create evaluation job.') from err\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a97fd62",
      "metadata": {},
      "source": [
        "## Check Job Status\n",
        "Retrieve the evaluation job status to confirm that it is running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "de30888f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"ResponseMetadata\": {\n",
            "    \"RequestId\": \"b49565fd-12c3-41b4-9db4-4fa28db2c3ee\",\n",
            "    \"HTTPStatusCode\": 200,\n",
            "    \"HTTPHeaders\": {\n",
            "      \"date\": \"Mon, 29 Sep 2025 15:28:03 GMT\",\n",
            "      \"content-type\": \"application/json\",\n",
            "      \"content-length\": \"1443\",\n",
            "      \"connection\": \"keep-alive\",\n",
            "      \"x-amzn-requestid\": \"b49565fd-12c3-41b4-9db4-4fa28db2c3ee\"\n",
            "    },\n",
            "    \"RetryAttempts\": 0\n",
            "  },\n",
            "  \"jobName\": \"baseline-eval-job-20250929-232655\",\n",
            "  \"status\": \"InProgress\",\n",
            "  \"jobArn\": \"arn:aws:bedrock:us-west-2:187899929471:evaluation-job/ks5dd1pskn07\",\n",
            "  \"roleArn\": \"arn:aws:iam::187899929471:role/service-role/Amazon-Bedrock-IAM-Role-20250928T210855\",\n",
            "  \"jobType\": \"Automated\",\n",
            "  \"applicationType\": \"ModelEvaluation\",\n",
            "  \"evaluationConfig\": {\n",
            "    \"automated\": {\n",
            "      \"datasetMetricConfigs\": [\n",
            "        {\n",
            "          \"taskType\": \"General\",\n",
            "          \"dataset\": {\n",
            "            \"name\": \"GeneralTriviaNoGroundTruth\",\n",
            "            \"datasetLocation\": {\n",
            "              \"s3Uri\": \"s3://riley-inc-rag-knowledge-base-20250929-210517/prompt_datasets/general_trivia_no_groundtruth.jsonl\"\n",
            "            }\n",
            "          },\n",
            "          \"metricNames\": [\n",
            "            \"Builtin.Correctness\",\n",
            "            \"Builtin.Completeness\",\n",
            "            \"Builtin.Faithfulness\",\n",
            "            \"Builtin.Helpfulness\",\n",
            "            \"Builtin.Coherence\",\n",
            "            \"Builtin.Relevance\",\n",
            "            \"Builtin.FollowingInstructions\",\n",
            "            \"Builtin.ProfessionalStyleAndTone\",\n",
            "            \"Builtin.Harmfulness\",\n",
            "            \"Builtin.Stereotyping\",\n",
            "            \"Builtin.Refusal\"\n",
            "          ]\n",
            "        }\n",
            "      ],\n",
            "      \"evaluatorModelConfig\": {\n",
            "        \"bedrockEvaluatorModels\": [\n",
            "          {\n",
            "            \"modelIdentifier\": \"us.amazon.nova-pro-v1:0\"\n",
            "          }\n",
            "        ]\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"inferenceConfig\": {\n",
            "    \"models\": [\n",
            "      {\n",
            "        \"bedrockModel\": {\n",
            "          \"modelIdentifier\": \"us.amazon.nova-lite-v1:0\",\n",
            "          \"inferenceParams\": \"{}\"\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  \"outputDataConfig\": {\n",
            "    \"s3Uri\": \"s3://riley-inc-rag-eval-results-20250929-210517/baseline-evals/model-judge-run-20250929-232500/\"\n",
            "  },\n",
            "  \"creationTime\": \"2025-09-29 15:26:56.642000+00:00\",\n",
            "  \"lastModifiedTime\": \"2025-09-29 15:26:56.642000+00:00\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "job_arn = create_response.get('jobArn') or create_response.get('evaluationJobArn')\n",
        "if not job_arn:\n",
        "    raise ValueError('Could not find the job ARN in the create response.')\n",
        "\n",
        "try:\n",
        "    job_details = bedrock.get_evaluation_job(jobIdentifier=job_arn)\n",
        "    print(json.dumps(job_details, indent=2, default=str))\n",
        "except (ClientError, BotoCoreError) as err:\n",
        "    raise RuntimeError('Unable to fetch evaluation job status.') from err\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "04d5ed97",
      "metadata": {},
      "outputs": [],
      "source": [
        "def launch_eval_job(model_id: str, task_type: str, datasets: list, metrics: list, evaluator_config: dict):\n",
        "    if not isinstance(datasets, list) or not datasets:\n",
        "        raise ValueError('datasets must be a non-empty list of dataset definitions.')\n",
        "    if not isinstance(metrics, list) or not metrics:\n",
        "        raise ValueError('metrics must be a non-empty list of metric names.')\n",
        "    if not isinstance(evaluator_config, dict) or 'bedrockEvaluatorModels' not in evaluator_config:\n",
        "        raise ValueError('evaluator_config must include bedrockEvaluatorModels.')\n",
        "\n",
        "    dataset_metric_configs = []\n",
        "    for dataset in datasets:\n",
        "        if isinstance(dataset, str):\n",
        "            dataset_metric_configs.append({\n",
        "                'taskType': task_type,\n",
        "                'dataset': {\n",
        "                    'name': 'CustomDataset',\n",
        "                    'datasetLocation': {'s3Uri': dataset}\n",
        "                },\n",
        "                'metricNames': metrics\n",
        "            })\n",
        "        elif isinstance(dataset, dict) and 'datasetLocation' in dataset:\n",
        "            dataset_metric_configs.append({\n",
        "                'taskType': task_type,\n",
        "                'dataset': deepcopy(dataset),\n",
        "                'metricNames': metrics\n",
        "            })\n",
        "        else:\n",
        "            raise ValueError('Each dataset entry must be a dataset string or dict with datasetLocation.')\n",
        "\n",
        "    sanitized_model = re.sub(r'[^a-zA-Z0-9-]+', '-', model_id.split('/')[-1])\n",
        "    job_suffix = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "    job_name = f\"baseline-eval-job-{sanitized_model}-{job_suffix}\"\n",
        "\n",
        "    request_payload = {\n",
        "        'jobName': job_name,\n",
        "        'roleArn': role_arn,\n",
        "        'applicationType': application_type,\n",
        "        'evaluationConfig': {\n",
        "            'automated': {\n",
        "                'datasetMetricConfigs': dataset_metric_configs,\n",
        "                'evaluatorModelConfig': evaluator_config\n",
        "            }\n",
        "        },\n",
        "        'inferenceConfig': {\n",
        "            'models': [\n",
        "                {\n",
        "                    'bedrockModel': {\n",
        "                        'modelIdentifier': model_id\n",
        "                    }\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        'outputDataConfig': {\n",
        "            's3Uri': shared_output_uri\n",
        "        }\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = bedrock.create_evaluation_job(**request_payload)\n",
        "    except (ClientError, BotoCoreError) as err:\n",
        "        raise RuntimeError(f'Failed to create evaluation job for {model_id}.') from err\n",
        "\n",
        "    job_arn = response.get('jobArn') or response.get('evaluationJobArn')\n",
        "    print(f\"Launched {job_name} (model={model_id}) -> {job_arn}\")\n",
        "    return {\n",
        "        'job_name': job_name,\n",
        "        'job_arn': job_arn,\n",
        "        'response': response\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Launch Batch of Model-as-a-Judge Eval Jobs\n",
        "Trigger three evaluations for different Nova-family models, sending all outputs to the shared comparison folder and explicitly referencing the evaluator configuration for clarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launched baseline-eval-job-us-amazon-nova-lite-v1-0-20250929-233009 (model=us.amazon.nova-lite-v1:0) -> arn:aws:bedrock:us-west-2:187899929471:evaluation-job/cd3wock08fmg\n",
            "Launched baseline-eval-job-us-amazon-nova-micro-v1-0-20250929-233011 (model=us.amazon.nova-micro-v1:0) -> arn:aws:bedrock:us-west-2:187899929471:evaluation-job/lg3t3axuzgwo\n",
            "Launched baseline-eval-job-us-amazon-nova-pro-v1-0-20250929-233012 (model=us.amazon.nova-pro-v1:0) -> arn:aws:bedrock:us-west-2:187899929471:evaluation-job/21qda9111ffq\n",
            "[\n",
            "  {\n",
            "    \"job_name\": \"baseline-eval-job-us-amazon-nova-lite-v1-0-20250929-233009\",\n",
            "    \"job_arn\": \"arn:aws:bedrock:us-west-2:187899929471:evaluation-job/cd3wock08fmg\",\n",
            "    \"response\": {\n",
            "      \"ResponseMetadata\": {\n",
            "        \"RequestId\": \"69de510b-d45c-472f-a4f9-251c22f55d2b\",\n",
            "        \"HTTPStatusCode\": 202,\n",
            "        \"HTTPHeaders\": {\n",
            "          \"date\": \"Mon, 29 Sep 2025 15:30:11 GMT\",\n",
            "          \"content-type\": \"application/json\",\n",
            "          \"content-length\": \"79\",\n",
            "          \"connection\": \"keep-alive\",\n",
            "          \"x-amzn-requestid\": \"69de510b-d45c-472f-a4f9-251c22f55d2b\"\n",
            "        },\n",
            "        \"RetryAttempts\": 0\n",
            "      },\n",
            "      \"jobArn\": \"arn:aws:bedrock:us-west-2:187899929471:evaluation-job/cd3wock08fmg\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"job_name\": \"baseline-eval-job-us-amazon-nova-micro-v1-0-20250929-233011\",\n",
            "    \"job_arn\": \"arn:aws:bedrock:us-west-2:187899929471:evaluation-job/lg3t3axuzgwo\",\n",
            "    \"response\": {\n",
            "      \"ResponseMetadata\": {\n",
            "        \"RequestId\": \"025abe6b-cbe7-46e8-a759-424b00e2b290\",\n",
            "        \"HTTPStatusCode\": 202,\n",
            "        \"HTTPHeaders\": {\n",
            "          \"date\": \"Mon, 29 Sep 2025 15:30:12 GMT\",\n",
            "          \"content-type\": \"application/json\",\n",
            "          \"content-length\": \"79\",\n",
            "          \"connection\": \"keep-alive\",\n",
            "          \"x-amzn-requestid\": \"025abe6b-cbe7-46e8-a759-424b00e2b290\"\n",
            "        },\n",
            "        \"RetryAttempts\": 0\n",
            "      },\n",
            "      \"jobArn\": \"arn:aws:bedrock:us-west-2:187899929471:evaluation-job/lg3t3axuzgwo\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"job_name\": \"baseline-eval-job-us-amazon-nova-pro-v1-0-20250929-233012\",\n",
            "    \"job_arn\": \"arn:aws:bedrock:us-west-2:187899929471:evaluation-job/21qda9111ffq\",\n",
            "    \"response\": {\n",
            "      \"ResponseMetadata\": {\n",
            "        \"RequestId\": \"e616efe4-0acb-45dc-8b4e-a5a889b0e726\",\n",
            "        \"HTTPStatusCode\": 202,\n",
            "        \"HTTPHeaders\": {\n",
            "          \"date\": \"Mon, 29 Sep 2025 15:30:14 GMT\",\n",
            "          \"content-type\": \"application/json\",\n",
            "          \"content-length\": \"79\",\n",
            "          \"connection\": \"keep-alive\",\n",
            "          \"x-amzn-requestid\": \"e616efe4-0acb-45dc-8b4e-a5a889b0e726\"\n",
            "        },\n",
            "        \"RetryAttempts\": 0\n",
            "      },\n",
            "      \"jobArn\": \"arn:aws:bedrock:us-west-2:187899929471:evaluation-job/21qda9111ffq\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "Evaluator model config used: {\n",
            "  \"bedrockEvaluatorModels\": [\n",
            "    {\n",
            "      \"modelIdentifier\": \"us.amazon.nova-pro-v1:0\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "candidate_models = [\n",
        "    'us.amazon.nova-lite-v1:0',\n",
        "    'us.amazon.nova-micro-v1:0',\n",
        "    'us.amazon.nova-pro-v1:0'\n",
        "]\n",
        "\n",
        "metrics = llm_judge_metrics\n",
        "\n",
        "batch_jobs = []\n",
        "for candidate_model in candidate_models:\n",
        "    job_info = launch_eval_job(\n",
        "        model_id=candidate_model,\n",
        "        task_type=judge_task_type,\n",
        "        datasets=datasets,\n",
        "        metrics=metrics,\n",
        "        evaluator_config=evaluator_model_config\n",
        "    )\n",
        "    batch_jobs.append(job_info)\n",
        "\n",
        "print(json.dumps(batch_jobs, indent=2, default=str))\n",
        "print(f'Evaluator model config used: {json.dumps(evaluator_model_config, indent=2)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "- Monitor each job until it reaches a terminal state (`Completed`, `Failed`, or `Stopped`).\n",
        "- Review judge scores and rationales stored within the shared output prefix.\n",
        "- Compare candidate model performance side-by-side in the Bedrock console or by aggregating the S3 outputs."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
